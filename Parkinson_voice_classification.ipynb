{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Parkinson’s Disease Detection using Voice Biomarkers**\n",
        "This notebook explores the use of ML classifiers (Logistic Regression, XGBoost, Platt-Calibrated SVC) to predict early-stage Parkinson’s Disease based on voice features.\n"
      ],
      "metadata": {
        "id": "vARqHB1EeEK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Importing Libraries**"
      ],
      "metadata": {
        "id": "bTcxMa6cSWcR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIovdBiWQWKe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Data Loading**"
      ],
      "metadata": {
        "id": "GGrMJlWKS02_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "if not os.path.exists('parkinson_disease.csv'):\n",
        "    files.upload()\n",
        "\n",
        "df = pd.read_csv('parkinson_disease.csv')\n",
        "pd.set_option('display.max_columns', 10)\n",
        "df.sample(5)\n"
      ],
      "metadata": {
        "id": "oTKbnX2WQqAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "BiCjIZN3W1qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display dataset info: data types, nulls, memory usage\n",
        "df.info()"
      ],
      "metadata": {
        "id": "lUjlCEvaRa7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transposed describe for better view across all columns\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "NqzqJaYzReNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check total number of missing values\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "l-Wk2hrJRhiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Data Preprocessing**\n",
        "\n",
        "\n",
        "We start by normalizing the features using Min-Max Scaling and applying chi-squared feature selection to retain the top 30 informative features.\n"
      ],
      "metadata": {
        "id": "KsgMAanyUToi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['class'])"
      ],
      "metadata": {
        "id": "_zJ9Xp56Ua0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the target column is 'status' or similar\n",
        "if df['class'].dtype == 'object':\n",
        "    le = LabelEncoder()\n",
        "    df['class'] = le.fit_transform(df['class'])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['class'])\n",
        "y = df['class']\n",
        "\n",
        "# Normalize features to [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "X_scaled.head()\n"
      ],
      "metadata": {
        "id": "cWiBbi3KWMpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.2 Removing Highly Correlated Features**\n",
        "\n",
        "Highly correlated features (correlation > 0.7) can introduce redundancy and harm model performance.\n",
        "We group the dataset by `id`, drop it, and then remove one feature from each pair that is strongly correlated."
      ],
      "metadata": {
        "id": "yNKj8JiVWotZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'id' and average duplicates\n",
        "df = df.groupby('id').mean().reset_index()\n",
        "\n",
        "# Drop 'id' as it's no longer needed\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# Remove features with high correlation (> 0.7)\n",
        "target_col = 'class'\n",
        "columns = list(df.columns)\n",
        "columns.remove(target_col)\n",
        "\n",
        "filtered_columns = []\n",
        "\n",
        "for i, col in enumerate(columns):\n",
        "    keep = True\n",
        "    for sel in filtered_columns:\n",
        "        if abs(df[col].corr(df[sel])) > 0.7:\n",
        "            keep = False\n",
        "            break\n",
        "    if keep:\n",
        "        filtered_columns.append(col)\n",
        "\n",
        "# Add back the target column\n",
        "filtered_columns.append(target_col)\n",
        "df = df[filtered_columns]\n",
        "\n",
        "print(\"Remaining shape after removing correlated features:\", df.shape)\n"
      ],
      "metadata": {
        "id": "ChBDO3g9Rj8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class balance\n",
        "plt.figure(figsize=(6, 4))\n",
        "df['class'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title('Class Distribution')\n",
        "plt.xticks(ticks=[0, 1], labels=['Healthy', 'Parkinson'], rotation=0)\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "corr = df.corr()\n",
        "sb.heatmap(corr, cmap='coolwarm', annot=False)\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dw6bp1hhRh9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature Selection and Class Distribution Analysis 🔍📊\n",
        "To reduce dimensionality and improve model efficiency, we use the Chi-squared test to select the top 30 features that have the strongest relationship with the target variable (`class`).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lAjSGbtdYGki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 🧠 **Note:** Chi-squared test works with non-negative values only (it assumes frequency data), so we normalize features to **[0, 1] range**.\n"
      ],
      "metadata": {
        "id": "OMIgRap70oUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Separating features and target\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Normalizing features (required for Chi-squared test)\n",
        "# Chi-squared test assumes non-negative input features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Applying Chi-squared test to select top 30 features\n",
        "selector = SelectKBest(score_func=chi2, k=30)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "\n",
        "# Getting names of selected features\n",
        "selected_mask = selector.get_support()\n",
        "selected_columns = X.columns[selected_mask]\n",
        "\n",
        "# Displaying selected features with their Chi-squared scores\n",
        "feature_scores = selector.scores_[selected_mask]\n",
        "chi2_scores_df = pd.DataFrame({'Feature': selected_columns, 'Chi2 Score': feature_scores})\n",
        "chi2_scores_df = chi2_scores_df.sort_values(by='Chi2 Score', ascending=False)\n",
        "print(\"Top 30 features with Chi-squared scores:\")\n",
        "display(chi2_scores_df)\n",
        "\n",
        "\n",
        "# Creating filtered DataFrame with selected features and target\n",
        "df = pd.DataFrame(X_selected, columns=selected_columns)\n",
        "df['class'] = y.reset_index(drop=True)  # Ensuring alignment with transformed X\n",
        "\n",
        "print(\"Shape after Chi-squared feature selection:\", df.shape)"
      ],
      "metadata": {
        "id": "9vIygg3FYGMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Class Distribution Visualization\n",
        "\n",
        "Before splitting the data, we examine the class balance to understand if the dataset is skewed toward any particular label. This informs our sampling strategy."
      ],
      "metadata": {
        "id": "rfgvFIhmZrUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class distribution - Pie Chart\n",
        "class_counts = df['class'].value_counts()\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(class_counts.values,\n",
        "        labels=class_counts.index,\n",
        "        autopct='%1.1f%%',\n",
        "        colors=['#FFA500', '#1f77b4'],\n",
        "        startangle=90)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "# Class distribution - Bar Plot (for actual counts)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.countplot(x='class', data=df, palette=['#FFA500', '#1f77b4'])\n",
        "plt.title(\"Class Counts\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oU2wUbEQZxRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Model Training and Evaluation**\n",
        "We train three different classifiers — Logistic Regression, XGBoost, and SVM — on the Parkinson’s dataset.\n",
        "To address the class imbalance (~75% positive class), we use RandomOverSampler during training.\n",
        "\n",
        "Each model is evaluated using ROC AUC score on both training and validation sets.\n"
      ],
      "metadata": {
        "id": "e2ovbt3RbuS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Stratified Cross-Validation & Oversampling Setup"
      ],
      "metadata": {
        "id": "2LlPeECNm_qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# Preparing data\n",
        "features = df.drop('class', axis=1)\n",
        "target = df['class']\n",
        "\n",
        "# Stratified K-Fold Cross Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Model definitions with class balancing\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "    \"SVC (Platt Calibrated)\": CalibratedClassifierCV(SVC(kernel='rbf', probability=True), method='sigmoid', cv=3)\n",
        "}\n"
      ],
      "metadata": {
        "id": "kKm3oaQuTfa4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.columns)\n",
        "print(features.dtypes)\n"
      ],
      "metadata": {
        "id": "ISxeWDWn-Lyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Model Training, AUC Scoring & Confidence Intervals"
      ],
      "metadata": {
        "id": "QSFrDfqqnBRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 🧪 Train-Test Split\n",
        "\n",
        "We split the data into training and test sets using stratified sampling to maintain class distribution.\n"
      ],
      "metadata": {
        "id": "JaWkMoWvfBHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n🔍 Training model: {name}\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict probabilities or scores\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        val_probs = model.predict_proba(X_val)[:, 1]\n",
        "    elif hasattr(model, \"decision_function\"):\n",
        "        val_probs = model.decision_function(X_val)\n",
        "    else:\n",
        "        print(f\"⚠️ Skipping {name}: No probability or decision function.\")\n",
        "        continue\n",
        "\n",
        "    if len(val_probs) != len(y_val):\n",
        "        print(f\"❌ Length mismatch for {name}\")\n",
        "        continue\n",
        "\n",
        "    # ROC-AUC & PR-AUC\n",
        "    roc_auc = roc_auc_score(y_val, val_probs)\n",
        "    precision, recall, _ = precision_recall_curve(y_val, val_probs)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"ROC_AUC\": roc_auc,\n",
        "        \"PR_AUC\": pr_auc,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall\n",
        "    })\n",
        "\n",
        "# Print result table\n",
        "print(\"\\n📊 Table Summary of Results\")\n",
        "print(f\"{'Model':<20} {'ROC-AUC':<10} {'PR-AUC':<10}\")\n",
        "print(\"-\" * 42)\n",
        "for r in results:\n",
        "    print(f\"{r['Model']:<20} {r['ROC_AUC']:.2f}      {r['PR_AUC']:.2f}\")\n",
        "\n",
        "# PR Curves\n",
        "for r in results:\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(r[\"Recall\"], r[\"Precision\"], label=f\"{r['Model']} (AUC = {r['PR_AUC']:.2f})\", linewidth=2)\n",
        "    plt.xlabel(\"Recall\", fontsize=12)\n",
        "    plt.ylabel(\"Precision\", fontsize=12)\n",
        "    plt.title(f\"{r['Model']} Precision-Recall Curve\", fontsize=13, weight='bold')\n",
        "    plt.legend(loc='lower left', fontsize=10)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "oktcFsLOpUC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📊 Table Summary of Results\n",
        "\n",
        "| Model                  | ROC-AUC | PR-AUC |\n",
        "| ---------------------- | ------- | ------ |\n",
        "| Logistic Regression    | 0.77    | 0.90   |\n",
        "| Random Forest          | 0.78    | 0.91   |\n",
        "| SVC (Platt Calibrated) | 0.73    | 0.88   |\n",
        "\n"
      ],
      "metadata": {
        "id": "xKQ567xEp_VO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✅ Observations\n",
        "\n",
        "- All models are evaluated using **Stratified 5-Fold Cross Validation** to ensure class distribution consistency across folds.\n",
        "- To mitigate class imbalance (~75% positive), **RandomOverSampler** is applied in each fold before training.\n",
        "- Performance metrics include both **ROC-AUC** (sensitivity-specificity tradeoff) and **PR-AUC** (more informative under imbalance).\n",
        "- **Support Vector Machine (SVC)** is calibrated using **Platt Scaling** to enable reliable probability outputs for interpretability (e.g., in SHAP analysis).\n",
        "- Evaluation focuses on **average ROC-AUC and PR-AUC values** across folds for fair comparison of model performance.\n"
      ],
      "metadata": {
        "id": "C1vRgZI9nOBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 95% confidence interval quantifies the uncertainty in ROC-AUC estimation across folds. A narrow CI indicates stable model performance, which is important for clinical applicability.\n"
      ],
      "metadata": {
        "id": "uwzM7DOYqND3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Classification Report — All Models\n",
        "\n",
        "\n",
        "Precision, recall, and F1-score are reported for each model, giving insight into how well they handle both classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "DHe1X9QOcxy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"📌 Classification Reports\\n\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{name}\")\n",
        "    y_pred = model.predict(X_val)\n",
        "    print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "id": "6VbHLQT1VdpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📊 Classification Report Summary\n",
        "\n",
        "**Understanding the Averages:**\n",
        "- **Macro Avg**: Gives equal weight to each class — useful to assess model fairness.\n",
        "- **Weighted Avg**: Adjusts metrics based on class distribution — useful when data is imbalanced.\n",
        "\n",
        "---\n",
        "\n",
        "**🧪 Dataset Note:**\n",
        "- Class **1 (Parkinson’s)** has **higher support (~74%)**.\n",
        "- Pay close attention to **Class 0 (Healthy)** metrics, especially **recall**, to avoid false positives.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔍 Model-wise Observations:\n",
        "\n",
        "- **📌 Logistic Regression**\n",
        "  - Balanced performance across both classes.\n",
        "  - **Recall for Class 0 = 0.69** → Detects most healthy individuals.\n",
        "  - Weighted F1-score: **0.76**\n",
        "\n",
        "- **📌 Random Forest**\n",
        "  - Very strong at detecting Parkinson’s (**Recall = 0.92**).\n",
        "  - **Recall for Class 0 = 0.31** → Misses many healthy individuals.\n",
        "  - May overfit to the majority class despite good overall accuracy (**76%**).\n",
        "\n",
        "- **📌 SVC (Platt Calibrated)**\n",
        "  - **Recall for Class 0 = 0.38**, an improvement over earlier results.\n",
        "  - Excellent detection of Parkinson’s (**Recall = 0.95**).\n",
        "  - Most balanced performance in terms of precision-recall tradeoff.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Takeaway:\n",
        "> Even when overall accuracy is high, always examine **recall for the minority class (Class 0)** — especially in medical applications where misclassification can carry high risk.\n"
      ],
      "metadata": {
        "id": "GCXqu2Jjra4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Confusion Matrices – All Models\n",
        "\n",
        "\n",
        "\n",
        "These matrices provide a breakdown of true/false positives and negatives for each model on the validation set. They help evaluate model behavior more concretely.\n",
        "\n",
        "\n",
        "The confusion matrices below show the classification results on the validation set for each model. In each matrix, you can observe:\n",
        "\n",
        "- **True Positives (TP)** – Bottom-right: Parkinson’s correctly identified  \n",
        "- **True Negatives (TN)** – Top-left: Healthy correctly identified  \n",
        "- **False Positives (FP)** – Top-right: Healthy misclassified as Parkinson’s  \n",
        "- **False Negatives (FN)** – Bottom-left: Parkinson’s misclassified as Healthy  \n",
        "\n",
        "These visualizations help us evaluate how well each model distinguishes between healthy individuals and those with Parkinson’s Disease.\n"
      ],
      "metadata": {
        "id": "b-xxjT0rvrJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 🧠 **Note:** In this dataset, **Class 0 = Healthy** and **Class 1 = Parkinson's Disease**.\n"
      ],
      "metadata": {
        "id": "Gw16t8BOwI2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "print(\"📌 Confusion Matrices\\n\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Predicting on validation set from the last fold\n",
        "    y_pred = model.predict(X_val)\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5, 4))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Healthy', \"Parkinson's\"])\n",
        "    disp.plot(cmap=plt.cm.Blues, values_format='d', ax=ax)\n",
        "\n",
        "    ax.set_title(f\"Confusion Matrix – {name}\", fontsize=12)\n",
        "    ax.set_xlabel(\"Predicted Label\")\n",
        "    ax.set_ylabel(\"True Label\")\n",
        "    ax.grid(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "zyKP413gwPIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔍 Observation – Logistic Regression\n",
        "\n",
        "Confusion Matrix:  \n",
        "[[9,4],\n",
        "[9, 29]]\n",
        "\n",
        "✅ Parkinson’s (Class 1) detection remains strong with 29 true positives.\n",
        "\n",
        "⚠️ 9 Parkinson’s cases are missed and predicted as Healthy (false negatives), which is risky in medical screening.\n",
        "\n",
        "⚠️ 4 Healthy individuals are incorrectly flagged as having Parkinson’s (false positives).\n",
        "\n",
        "✅ Class 0 recall has improved slightly (9 out of 13), but false negatives for Parkinson’s remain a key concern.\n",
        "\n",
        "Overall, Logistic Regression maintains good detection for Parkinson’s but still needs refinement to minimize false negatives — crucial in clinical settings."
      ],
      "metadata": {
        "id": "WPaHhRjcxFZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔍 Observation – Random Forest\n",
        "\n",
        "Confusion Matrix:  \n",
        "[[4,9],\n",
        "[3, 35]]\n",
        "\n",
        "✅ Parkinson’s detection is excellent with 35 true positives and only 3 false negatives, showing high sensitivity.\n",
        "\n",
        "⚠️ 9 Healthy individuals were incorrectly predicted as having Parkinson’s (false positives), which reduces specificity.\n",
        "\n",
        "✅ Only 4 true negatives were correctly identified as Healthy, indicating some challenge in distinguishing non-Parkinson’s cases.\n",
        "\n",
        "Overall, the model strongly favors identifying Parkinson’s, which is valuable in clinical screening — but the high number of false positives may require further calibration or tuning to avoid unnecessary concern for healthy individuals.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ROC2oYVDxUST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔍 Observation – SVC (Platt Calibrated)\n",
        "\n",
        "Confusion Matrix:  \n",
        "[[5, 8],\n",
        "[2, 36]]\n",
        "\n",
        "✅ 36 true positives and only 2 false negatives show high sensitivity in detecting Parkinson’s.\n",
        "\n",
        "⚠️ 8 Healthy individuals were misclassified as Parkinson’s (false positives), impacting the model’s specificity.\n",
        "\n",
        "✅ 5 true negatives indicate some ability to correctly identify Healthy individuals — better than before.\n",
        "\n",
        "Overall, the model maintains a good balance, excelling in Parkinson’s detection while moderately improving its identification of Healthy cases compared to earlier performance. With further tuning, it could become a solid screening tool in clinical contexts."
      ],
      "metadata": {
        "id": "dUPMYx87xcpq"
      }
    }
  ]
}