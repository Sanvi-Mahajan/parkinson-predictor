# ğŸ§  Parkinsonâ€™s Disease Prediction Using Voice Features  
_Clinical Screening using Machine Learning_

## ğŸ“Œ Project Overview  
This project builds a machine learning pipeline to predict Parkinsonâ€™s disease using acoustic features extracted from voice recordings. The dataset contains biomedical voice measurements which reflect vocal impairment â€” a hallmark symptom of Parkinsonâ€™s.

## ğŸ“‚ Dataset Summary  
- **Source**: [Geeks For Geeks](https://media.geeksforgeeks.org/wp-content/uploads/20250122143413596644/parkinson_disease.csv).
- It includes biomedical voice measurements from people with and without Parkinsonâ€™s disease.
- **Total Samples:** 756  
- **Total Features:** 754 (after preprocessing)  
- **Target Variable:** `class` â†’  
  - `1` = Parkinsonâ€™s  
  - `0` = Healthy  
- **Class Distribution:**  
  - Parkinsonâ€™s (Class 1): 564 samples (74.6%)  
  - Healthy (Class 0): 192 samples (25.4%)

## ğŸ§ª Key Voice Features  
Includes various measures such as:  
- **Jitter**, **Shimmer**, **HNR** (Harmonic-to-Noise Ratio)  
- **PPE** (Pitch Period Entropy)  
- **DFA** (Detrended Fluctuation Analysis)  
- **RPDE** (Recurrence Period Density Entropy)

## ğŸ§ª Technologies Used

- Python ğŸ
- scikit-learn (Logistic Regression, Random Forest, SVC)
- imbalanced-learn (RandomOverSampler)
- Matplotlib & Seaborn (for visualization)
- pandas, numpy

## âš™ï¸ Workflow

1. **Data Exploration & Cleaning**
   - Removed irrelevant columns (e.g., `name`)
   - Checked class distribution
2. **Feature Selection**
   - Applied Chi-squared test to select top 30 features
3. **Class Imbalance Handling**
   - Used `RandomOverSampler` to balance classes before model training
4. **Model Training & Validation**
   - Logistic Regression (balanced)
   - Random Forest (balanced)
   - Support Vector Classifier (Platt Calibrated)
5. **Evaluation Metrics**
   - ROC-AUC and PR-AUC scores
   - Classification reports (precision, recall, F1)
   - Confusion matrices
6. **Visualization**
   - Class distribution plots
   - Precision-Recall curves
   - Chi-squared feature importance



## ğŸ” Initial Exploration

- Loaded the dataset (`parkinson_disease.csv`) and verified shape: 757 rows Ã— 755 columns.
- No missing values detected.
- Performed statistical summary using `.describe()` and `.info()`.
- Observed class imbalance: more Parkinsonâ€™s samples than Healthy.

## ğŸ§¼ Preprocessing Steps

1. **Drop Identifier Columns**
   - Dropped `id` or `name` columns, as they do not contribute to prediction.
2. **Averaged Duplicate Entries**
   - If a subject has multiple recordings, their feature values are averaged by ID.
3. **Correlation Filtering**
   - Removed features with high Pearson correlation (|r| > 0.7) to prevent multicollinearity.
4. **Class Distribution Visualization**
   - Visualized class imbalance using bar plots.
5. **Feature Selection**
   - Applied Chi-squared test to select the top 100 voice features.
6. **Train-Test Split**
   - Used stratified 80-20 split to maintain class proportions in both sets.

## ğŸ§  Models Used

We experimented with three classification models, all optimized for medical screening where class imbalance and precision are crucial:

- **Logistic Regression** (with `class_weight='balanced'`)  
  A lightweight linear model useful for interpretability and baseline benchmarking.

- **Random Forest Classifier** (with `class_weight='balanced'`)  
  An ensemble of decision trees â€” helps capture nonlinear patterns, but prone to overfitting on imbalanced data.

- **Support Vector Classifier (Platt-Calibrated)**  
  Used RBF kernel + probability calibration for better probabilistic outputs. Ideal for sensitive decision-making.

### âš–ï¸ Class Imbalance Handling

The dataset is **imbalanced** (â‰ˆ75% Parkinsonâ€™s, 25% Healthy). To ensure fair training:

- Applied `RandomOverSampler` during cross-validation to synthetically balance the classes.
- Also used `class_weight='balanced'` in applicable models to penalize misclassification of the minority class.

This ensured better recall for the Healthy class â€” critical in a clinical context where false positives/negatives have high cost.



## ğŸ” Cross-Validation & Evaluation Strategy

To ensure robust and fair evaluation of our models, we implemented the following strategy:

### ğŸ“Š Cross-Validation

- **Stratified K-Fold (k=5)**  
  Preserved the original class distribution (â‰ˆ75% Parkinsonâ€™s, 25% Healthy) in every fold.  
  This avoids biased evaluation due to imbalanced splits.

- **Oversampling within each fold**  
  Used `RandomOverSampler` to balance the training data in each fold without leaking test information.

**Visuals:**
- Class distribution (bar plot)
- Correlation heatmap (filtered)

### ğŸ§ª Evaluation Metrics

We used multiple metrics to get a holistic view of model performance:

- **ROC-AUC Score**  
  Measures tradeoff between **sensitivity** (true positive rate) and **specificity** (true negative rate).  
  Ideal for medical datasets with imbalanced classes.

- **PR-AUC (Precision-Recall Curve)**  
  Focuses on model performance for the **positive (Parkinsonâ€™s)** class. Useful when the dataset is skewed.

- **F1-Score**  
  Harmonic mean of precision and recall â€” especially helpful when **false negatives** and **false positives** both matter.

- **Classification Report**  
  Includes precision, recall, F1-score, and support for each class individually.

- **Confusion Matrix**  
  Visual breakdown of prediction outcomes:  
  - True Positives (TP), False Positives (FP)  
  - True Negatives (TN), False Negatives (FN)  
  Helps assess medical risk of misclassification.

## ğŸ“Š Model Performance

We evaluated all models using ROC-AUC and PR-AUC â€” two critical metrics for imbalanced classification, especially in medical domains.

| Model                  | ROC-AUC | PR-AUC |
|------------------------|---------|--------|
| Logistic Regression    | 0.77    | 0.90   |
| Random Forest          | 0.78    | 0.91   |
| SVC (Platt Calibrated) | 0.73    | 0.88   |

### âœ… Key Insights

- **Strong PR-AUC scores** across all models indicate reliable performance in identifying Parkinsonâ€™s cases, despite class imbalance.
- **Random Forest** edges out others in both ROC and PR space, showing strong sensitivity and precision.
- **SVC**, though slightly behind, still performs well and offers calibrated probability outputs for downstream analysis.

## ğŸ“ˆ Classification Reports

### Logistic Regression
- Recall (Healthy): 0.69  
- Recall (Parkinsonâ€™s): 0.76  
- Weighted F1-score: 0.76  

### Random Forest
- Recall (Healthy): 0.31 âš ï¸  
- Recall (Parkinsonâ€™s): 0.92  
- Weighted F1-score: 0.74  

### SVC (Platt Calibrated)
- Recall (Healthy): 0.38  
- Recall (Parkinsonâ€™s): 0.95 âœ…  
- Weighted F1-score: 0.78  

ğŸ” **Takeaway**: Even with high overall accuracy, recall for **Class 0 (Healthy)** is crucial to avoid false positives in real-world clinical screening scenarios.

---

## ğŸ§¾ Confusion Matrices

### Logistic Regression
[ [9, 4],
[9, 29] ]

âœ… 29 Parkinsonâ€™s cases correctly detected  
âš ï¸ 9 Parkinsonâ€™s missed (false negatives)  

### Random Forest
[ [4, 9],
[3, 35] ]

âœ… 35 Parkinsonâ€™s detected  
âš ï¸ High false positives for Healthy (9)

### SVC (Platt Calibrated)
[ [5, 8],
[2, 36] ]

âœ… Best Parkinsonâ€™s detection (36)  
âœ… Moderate improvement for Healthy detection (5 correct)

## ğŸ“Œ Conclusion

This project demonstrates the promise of using **voice-based features** to detect Parkinsonâ€™s disease through machine learning.

- High precision and recall for Parkinsonâ€™s cases make these models viable for screening.
- With **further tuning, calibration, and validation**, this pipeline can assist in **early-stage detection** and **continuous remote monitoring**.

â—**Future Work**:
- Incorporate actual **voice waveforms** for deep learning applications.
- Collaborate with clinicians for real-world deployment and feedback.


## ğŸ™‹â€â™€ï¸ Author

Sanvi Mahajan â€” Aspiring Data Scientist 
ğŸ“« [LinkedIn](https://www.linkedin.com/in/sanvi-mahajan-502955256/) - Let's connect!


